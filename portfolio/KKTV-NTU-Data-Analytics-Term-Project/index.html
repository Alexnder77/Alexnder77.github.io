<!doctype html><html><head><style>.header{position:absolute;top:0;left:0;width:100%;background-size:cover;box-shadow:0 2px 4px rgba(0,0,0,.1)}.navbar2{background-color:var(--light);padding:0 2em;display:flex;align-items:center;justify-content:space-between;position:relative;top:auto;z-index:10}.navbar2-menu{list-style:none;margin:0;padding:0;display:flex;display:flex}.navbar2-menu li{margin-left:20px}.navbar2-menu li a{text-decoration:none;font-size:16px;display:flex}.navbar2-menu li a:hover{text-decoration:underline}.image_style{position:absolute;left:0;width:100%;height:250px;background-image:url(/portfolio_assets/images/02.jpg);background-repeat:no-repeat;background-size:cover;transition:background-color .3s ease-in-out;box-shadow:0 2px 4px rgba(0,0,0,.1);filter:blur(5px);background-attachment:fixed;z-index:-1}body{justify-content:center;align-items:center;margin:0;padding-top:150px}.container{display:flex;position:relative;justify-content:center;flex-direction:row;flex-wrap:nowrap;align-items:start;padding:1em 8em 0;margin:0 auto;top:200px}.singlePage2{flex:1;max-width:900px;min-width:500px;padding:15px 25px 25px;background:var(--light);border-radius:15px;box-shadow:0 2px 4px rgba(0,0,0,.1)}.headerStyle{display:flex;justify-content:center}.tableOfContentContainer{flex:1;padding-left:25px;display:flex;flex-direction:column;justify-content:center;position:sticky;top:0}@media all and (max-width:750px){.tableOfContentContainer{display:none}.container{padding:1em}.singlePage2{min-width:-webkit-fill-available}}</style><head><meta charset=utf-8><meta name=description content="As a final project for my NTU datascience course we where challenged to participate in a private Kaggle competition NTU 111-2 Data Analytics Term Project | Kaggle."><meta property="og:title" content="KKTV - NTU Data Analytics Term Project"><meta property="og:description" content="As a final project for my NTU datascience course we where challenged to participate in a private Kaggle competition NTU 111-2 Data Analytics Term Project | Kaggle."><meta property="og:type" content="website"><meta property="og:image" content="https://alexnder77.github.io/icon.png"><meta property="og:url" content="https://alexnder77.github.io/portfolio/KKTV-NTU-Data-Analytics-Term-Project/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="KKTV - NTU Data Analytics Term Project"><meta name=twitter:description content="As a final project for my NTU datascience course we where challenged to participate in a private Kaggle competition NTU 111-2 Data Analytics Term Project | Kaggle."><meta name=twitter:image content="https://alexnder77.github.io/icon.png"><meta name=twitter:site content="alexand27264042"><title>KKTV - NTU Data Analytics Term Project</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://alexnder77.github.io//icon.png><link href=https://alexnder77.github.io/styles.6ed7dde6d032c878d24304d105eb6575.min.css rel=stylesheet><link href=https://alexnder77.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://alexnder77.github.io/js/darkmode.f73aec5dc5664d36fb5aa59a0daa1aca.min.js></script>
<script src=https://alexnder77.github.io/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://alexnder77.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://alexnder77.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://alexnder77.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://alexnder77.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://alexnder77.github.io/",fetchData=Promise.all([fetch("https://alexnder77.github.io/indices/linkIndex.bae6a5e8eea45020a928b6ee161f6ca0.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://alexnder77.github.io/indices/contentIndex.6aab73c83abfb9e93ea15a6407e70974.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://alexnder77.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://alexnder77.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/alexnder77.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=alexnder77.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><link rel=stylesheet href></head><body><div class=header id=header><nav class=navbar2 id=navbar2><a class="image avatar"><img href=/portfolio/about src=/portfolio_assets/images/logo.png alt="cant find image" width=50 height=50 border-radius=5px box-shadow="0 2px 4px 0.1" margin=0 min-width=50px></a><style>.navbar2-menu{list-style:none;margin:0;padding:0;display:flex;display:flex;justify-content:right;min-width:272px}@media(max-width:1234px){.navbar2-menu{justify-content:center}.navbar2-menu li{margin-left:20px}.navbar2-menu li a{text-decoration:none;font-size:16px;display:flex}.navbar2-menu li a:hover{text-decoration:underline}}</style><ul class=navbar2-menu><li><a href=/portfolio>Portfolio Home</a></li><li><a href=/portfolio/about>About</a></li><li><a href=/notes/>Notes</a></li></ul></nav><div class=image_style></div></div><div class=container><div class=singlePage2><header><h1 id=page-title><a class=root-title>KKTV - NTU Data Analytics Term Project</a></h1><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><p>As a final project for my <em>NTU datascience course</em> we where challenged to participate in a private Kaggle competition
<a href=https://www.kaggle.com/competitions/data-analytics-datagame/overview rel=noopener>NTU 111-2 Data Analytics Term Project | Kaggle</a>. In this article I will go through how I approached the challenge.</p><a href=#understanding-the-challenge-predicting-drama-watching-schedules><h2 id=understanding-the-challenge-predicting-drama-watching-schedules><span class=hanchor arialabel=Anchor># </span>Understanding the Challenge: Predicting Drama-Watching Schedules</h2></a><p>The challenge centered around the task of predicting when users would watch dramas in the upcoming week. The key to success lay in analyzing users past viewing schedules and extracting meaningful patterns and insights that could generalize to future behavior.</p><p>The data was supplied by KKTV Taiwan ([insert discription of KKTV]) with the following goals for the predictive model:</p><ol><li><strong>Timely Recommendations:</strong> By accurately predicting users drama-watching habits, KKTV aimed to offer personalized recommendations to users who were likely to have free time in the upcoming week. This could enhance user engagement and satisfaction.</li><li><strong>Optimizing Push Notifications:</strong> Another crucial aspect was the effective scheduling of push notifications. By aligning push messages with users&rsquo; anticipated viewing times, KKTV aimed to minimize intrusive interruptions and maintain a seamless user experience.</li></ol><p>More information can be found on the Kaggle page for the challenge:
<a href=https://www.kaggle.com/competitions/data-analytics-datagame/overview rel=noopener>NTU 111-2 Data Analytics Term Project | Kaggle</a></p><a href=#the-data><h3 id=the-data><span class=hanchor arialabel=Anchor># </span>The data</h3></a><p>The objective of the challenge was to predict in which timeslots the users will be active on KKTV within a week. Where each day is divided into four timeslots: 1h00, 9h00, 17h00, and 21h00, resulting in a total of 28 (4X7) timeslots to be predicted.</p><p>The data was provided in two versions: complete and light. The complete version containing the raw data from KKTV, while the light version already had been pre-processed into a simplified format (binary data of the user activity).</p><p>Since the preprocessed data lacks a lot of the features from the complete version, I decided to focus on the raw data and only using the light data as a benchmark. So for the rest of the article I will only be using the complete data set.</p><a href=#complete-data-features><h4 id=complete-data-features><span class=hanchor arialabel=Anchor># </span>complete data features</h4></a><p>Below follows a description of the features available in the complete data set.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>user_id:
</span></span><span class=line><span class=cl>De-identification user id. The training set has user_id 0~30459, while the testing set has user_id 30460~38075.
</span></span><span class=line><span class=cl>device_id:
</span></span><span class=line><span class=cl>De-identification device id.
</span></span><span class=line><span class=cl>session_id:
</span></span><span class=line><span class=cl>The set of consecutive events. It is unique for an individual user, but a session_id may map to multiple user_id.
</span></span><span class=line><span class=cl>platform:
</span></span><span class=line><span class=cl>The OS in which the event occurred. Four types in total.
</span></span><span class=line><span class=cl>internet_connection_type :
</span></span><span class=line><span class=cl>12 types in total.
</span></span><span class=line><span class=cl>event_time:
</span></span><span class=line><span class=cl>The timestamp of the event is logged.
</span></span><span class=line><span class=cl>title_id:
</span></span><span class=line><span class=cl>When the event is logged, the encoded title of the movie/drama the user is watching.
</span></span><span class=line><span class=cl>action_trigger:
</span></span><span class=line><span class=cl>The action triggers the event, 14 in total.
</span></span><span class=line><span class=cl>played_duration:
</span></span><span class=line><span class=cl>When the event is triggered, the length of the movie/drama has been played (in seconds).
</span></span><span class=line><span class=cl>title_in_simulcast:
</span></span><span class=line><span class=cl>If the drama is aired weekly, &#34;1&#34; is logged; otherwise, you see &#34;0&#34;. &#34;2&#34; means unknown.
</span></span></code></pre></td></tr></table></div></div><a href=#measurement-criteria><h3 id=measurement-criteria><span class=hanchor arialabel=Anchor># </span>Measurement criteria</h3></a><p>The measure of this competition is AUC, one is recommended here
<a href=https://medium.com/kkstream/auc-explained-85537509e3b3 rel=noopener>Articles introducing AUC</a>，As easy to understand and very vivid.</p><a href=#feature-engineering><h2 id=feature-engineering><span class=hanchor arialabel=Anchor># </span>Feature engineering</h2></a><p>I experimented with a lot of different approaches to this challenge and data exploration and cleaning was pretty straight forward, when it comes to the feature engineering I decided on two approaches. The first one being time based and the second being content based.</p><a href=#approach-1-time-based-features><h3 id=approach-1-time-based-features><span class=hanchor arialabel=Anchor># </span>Approach 1: Time based features</h3></a><p>For the time based features I focused only on the time, for each event in the event data. The reasoning behind this is that a user is likely to have time related behavior pattern when it comes to viewing activity ex. view shows during the same timeslot on Mondays.</p><p>In actually I tried 3 slightly different approaches to the time based feature:</p><p><img src=https://alexnder77.github.io//portfolio/attachment/timeSlotApproaches.excalidraw.png width=auto alt></p><ol><li>Split duration in the &ldquo;correct&rdquo; timeslots
This approach means we split the duration of each event based on the time slot cut of times, so that for example if we have a 4h event that starts in timeslot 0 and ends in timeslot 1, then the time in timeslot 0 will be added to timeslot 0, and the remaining time will be added to the next timeslot.</li></ol><p>pros</p><ul><li>More accurate when it comes to the amount of time each user is active in a given timeslot</li></ul><p>cons</p><ul><li>doesn&rsquo;t take into consideration how many &ldquo;events&rdquo; there are in the different timeslots (i.e. if a user has multiple events throughout the time slot, it will just sum up the active time)</li><li>more complicated to implement</li></ul><ol start=2><li>Add the whole duration to the start time timeslot
Calculate the start time of the event and add the whole duration to that timeslot.</li></ol><p>pros</p><ul><li>simpler than 1</li></ul><p>cons</p><ul><li>doesn&rsquo;t show the time spent active in each timeslot accurately, ex. if a user starts a 4h session 1min before timeslot x ends, the whole duration will be added to timeslot x, despite most of the duration actually being spent in the next timeslot.</li><li>also doesn&rsquo;t take into consideration how many &ldquo;events&rdquo; there are in the different timeslots.</li></ul><ol start=3><li>Number of event in each timeslot
Calculate the star time for each event and use that to calculate the number of events in a given timeslot.</li></ol><p>pros</p><ul><li>simple to implement</li><li>takes into consideration nr of events</li><li>more closely models the label data (since the thing we wanna predict is wheter a user is active during a certain timeslot not how much time they spend active)</li></ul><p>cons</p><ul><li>Doesn&rsquo;t take into consideration duration (an event that is 1min is counted the same as one that&rsquo;s 6h) (maybe possible to improve on this by also considering duration?)</li></ul><p>(Among these three approaches, the most effective one was the third approach, which considers the number of events in each timeslot. This may be attributed to the fact that the prediction task primarily revolves around whether there is any activity during a given timeslot rather than the exact amount of time spent. By leveraging the count of events, this approach provides a simplified yet meaningful representation of user engagement during specific time intervals.)</p><a href=#approach-2-content-based-features><h3 id=approach-2-content-based-features><span class=hanchor arialabel=Anchor># </span>Approach 2: Content based features</h3></a><p>For approach 2 the goal was to extract features based on the content. taking into consideration the popularity of different shows, similarity in watching habits across users, generating embeddings for dramas based on their shared viewership patterns etc.</p><p>In short the following steps where followed:</p><ol><li><strong>Drama Popularity Metrics Calculation:</strong><ul><li>Total views, unique users, and average completion ratio for each drama are calculated from the training data.</li></ul></li><li><strong>Drama Connections Filtering Based on Shared Users:</strong><ul><li>The median number of shared users among dramas is used as a threshold.</li><li>Drama connections are established based on shared users.</li><li>Drama pairs with shared users meeting or exceeding the threshold are retained.</li></ul></li><li><strong>Drama Embeddings with DeepWalk Algorithm:</strong><ul><li>The filtered drama pairs are used to construct a graph.</li><li>The DeepWalk algorithm, implemented using Node2Vec, generates low-dimensional embeddings for dramas based on their shared viewership patterns.</li><li>Drama embeddings capture the underlying relationships for downstream tasks.</li></ul></li><li><strong>User-Level Feature Extraction:</strong><ul><li>User-level features like total played duration, total views, and unique dramas watched are aggregated from the training data.</li></ul></li><li><strong>Merging Features and Data:</strong><ul><li>User and drama features are merged with the original training data using relevant identifiers.</li></ul></li><li><strong>Merging Drama Embeddings:</strong><ul><li>Drama embeddings are merged with the training data based on drama identifiers.</li></ul></li><li><strong>Data Formatting:</strong><ul><li>The final dataset is organized with one row per user, containing user-level features and associated drama features.</li></ul></li></ol><p>A more detailed overview of the steps taken (as well as the code used) to generate all of the different features can be found here:
<a href=https://github.com/Alexnder77/-IE5054- rel=noopener>GitHub - Alexnder77/-IE5054-: Some of my code for the NTU course 資料分析方法 (IE5054)</a></p><a href=#models><h2 id=models><span class=hanchor arialabel=Anchor># </span>Models</h2></a><p>When it comes to my approach to trying out different models, tuning them and evaluating their performance, in essence the following steps where taken for both features:</p><ol><li>Selecting the features to use</li><li>Separating the train data into train and validation set (using a 70-30 split)</li><li>Training and evaluating the base-model (compare against benchmark)</li><li>if the model did well, continue to hyperparameter tuning, trying to improve the score.</li><li>if the score gets high enough use it to make predictions on the test data</li></ol><a href=#benchmark><h3 id=benchmark><span class=hanchor arialabel=Anchor># </span>Benchmark</h3></a><p>To establish a good benchmark test the light data was used with a XGB model, after tweaking the model parameters a little succeeded in reaching an AUC score of 0.80833. This benchmark was later used to evaluate the performance of my other models with the custom features.</p><p>(Note: After the completion of the challenge, when the teams where presenting our work in class the wining team (Ying Train Yi Fa
<a href=https://www.kaggle.com/competitions/data-analytics-datagame/leaderboard rel=noopener>NTU 111-2 Data Analytics Term Project | Kaggle</a>) succeeded in getting a score of 0.83957 just from the light data using XGB and the right hyperparameters)</p><a href=#cnn><h3 id=cnn><span class=hanchor arialabel=Anchor># </span>CNN</h3></a><p>Score: 0.82589
<img src=https://alexnder77.github.io//portfolio/attachment/af79e82a10549af35665ed181f35358b.png width=auto alt></p><p>The Convolutional Neural Network (CNN) model is a deep learning architecture particularly effective in processing grid-like data, such as images or sequences. For the time-based features, the data was reshaped to take advantage of this to represent each user&rsquo;s engagement across different time slots as a sequence.</p><p>The model consists of multiple convolutional and pooling layers, which can learn relevant patterns from the sequential data. These patterns can capture user behaviors like peak engagement times during certain days or time intervals. The final dense layers with a sigmoid activation function output probabilities of user activity during each time slot. By training this model on your time-based feature data, it can learn to recognize temporal patterns in users&rsquo; viewing schedules and predict their engagement in different time slots.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>,</span> <span class=n>input_shape</span><span class=o>=</span><span class=p>[</span><span class=mi>32</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Flatten</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=s1>&#39;binary_crossentropy&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>             <span class=n>optimizer</span><span class=o>=</span><span class=s1>&#39;adam&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>             <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=n>batch_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=c1>#128</span>
</span></span><span class=line><span class=cl>          <span class=n>epochs</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>plot_losses</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=n>validation_data</span><span class=o>=</span><span class=p>(</span><span class=n>X_val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl><span class=n>score</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Test loss:&#39;</span><span class=p>,</span> <span class=n>score</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Test accuracy:&#39;</span><span class=p>,</span> <span class=n>score</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><a href=#cnn--lstm><h3 id=cnn--lstm><span class=hanchor arialabel=Anchor># </span>CNN + LSTM</h3></a><p>Score: 0.82664</p><p><img src=https://alexnder77.github.io//portfolio/attachment/00232cc70e2fdea639b5b82ef7eee1e0.png width=auto alt></p><p>This model was used to try to combine the advantages of CNN and LSTM (Long Short-Term Memory). Which should be especially suited for modeling sequential data with spatial patterns</p><p>The CNN layers extract local patterns from the sequence, while the LSTM layers capture longer-term dependencies.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>,</span> <span class=n>input_shape</span><span class=o>=</span><span class=p>[</span><span class=mi>32</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Conv2D</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>MaxPooling2D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#LSTM layers</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>TimeDistributed</span><span class=p>(</span><span class=n>Flatten</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>LSTM</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=n>return_sequences</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>LSTM</span><span class=p>(</span><span class=mi>256</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>Dense</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><a href=#xgb><h3 id=xgb><span class=hanchor arialabel=Anchor># </span>XGB</h3></a><p>SCORE 0.83112</p><p><img src=https://alexnder77.github.io//portfolio/attachment/2183f1111dff0cfd6be5a60e3d0f126d.png width=auto alt></p><p>parameter values:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;objective&#39;</span><span class=p>:</span> <span class=s1>&#39;binary:logistic&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;eval_metric&#39;</span><span class=p>:</span> <span class=s1>&#39;logloss&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;eta&#39;</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;subsample&#39;</span><span class=p>:</span> <span class=mf>0.8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;colsample_bytree&#39;</span><span class=p>:</span> <span class=mf>0.8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;lambda&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;alpha&#39;</span><span class=p>:</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl><span class=c1># Train the XGBoost model with early stopping</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>xgb</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dtrain</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_boost_round</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evals</span><span class=o>=</span><span class=p>[(</span><span class=n>dtest</span><span class=p>,</span> <span class=s1>&#39;eval&#39;</span><span class=p>)],</span>
</span></span><span class=line><span class=cl>    <span class=n>early_stopping_rounds</span><span class=o>=</span><span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><a href=#ensemble-learning><h3 id=ensemble-learning><span class=hanchor arialabel=Anchor># </span>Ensemble learning</h3></a><p>Two different Ensemble learning techniques was used to try to improve the score further. these techniques being weighted averaging and stacking.</p><a href=#weighted-averaging><h4 id=weighted-averaging><span class=hanchor arialabel=Anchor># </span>Weighted averaging</h4></a><p>Averaging in ensemble learning refers to combining the predictions of different models by simply taking the average of the predictions. in theory this can improve the result since some models ex. LSTM might be good at predicting certain time related features where as CNN or XGB might be better at predicting other relationships. So in theory by combining the different models we can take advantage of the strengths of different models at the same time.</p><p>The simplest way to do that is through simply averaging the predictions, another usually better way is to use weighted averaging by applying a weight to the different predictions.</p><p>So if we have the above mentioned models and they generate the predictions: $P_1 , P_2 \text{ and } P_3$ we get the weighted average (WA) by applying the weights $w_1, w_2, w_3$ like this:
$$WA = \frac{w_1P_1+w_2P_2+w_3P_3}{3} $$</p><p>Different weights where tried and the best combination came from combining the above 3 models with the weights: 0.4 (XGB), 0.3 (CNN) and 0.3 (CNN + LSTM) -> Score: 0.836</p><a href=#stacking><h4 id=stacking><span class=hanchor arialabel=Anchor># </span>Stacking</h4></a><p>A more advanced ensemble stacking approach was also tried, based on
<a href=https://medium.com/@kstseng/kktv-data-game-17-11-1st-place-solution-96b3d62c594c rel=noopener>Kaishen Tseng&rsquo;s work</a></p><p><img src=https://alexnder77.github.io//portfolio/attachment/65844e05059424cc3b6b594ffbfff47c.png width=auto alt>
source:
<a href=https://medium.com/@kstseng/kktv-data-game-17-11-1st-place-solution-96b3d62c594c rel=noopener>KKTV Data Game-17.11 1st Place Solution | by Kaishen Tseng | Medium</a></p><p>In short, 28 different base-models where created, one for each timeslot to be predicted. These models are trained on a subset of the train data then used to generate both train set and test set predictions.</p><p><img src=https://alexnder77.github.io//portfolio/attachment/4e1d0e6140e1269c4f7ad6f288686584.png width=auto alt>
source:
<a href=https://medium.com/@kstseng/kktv-data-game-17-11-1st-place-solution-96b3d62c594c rel=noopener>KKTV Data Game-17.11 1st Place Solution | by Kaishen Tseng | Medium</a></p><p>The train set predictions are then added to the input features (of the train set) and used to train the Stack model. This stack model is then used to make the final prediction on the test data combined with the test predictions from the previous base models.</p><p>Applying this stacking method was a lot more work than the previous methods, but for some reason the score didn&rsquo;t improve.</p><a href=#discussion><h2 id=discussion><span class=hanchor arialabel=Anchor># </span>Discussion</h2></a><p>This was my first Kaggle challenge and it was a lot of fun, even though my team&rsquo;s leaderboard position might not have been at the top, I&rsquo;m genuinely content with our achievements and the knowledge gained throughout the project.</p><p>Some Thoughts:</p><blockquote><p>The Content based features didn&rsquo;t score very well, its likely that there is a mistake somewhere, maybe in generating the &ldquo;Drama Embeddings&rdquo; since its hard to tell what these values mean once they are generated.</p></blockquote><blockquote><p>the team that won the challenge did so using the light data set, meaning that its possible to get a very good score using that.</p></blockquote><ol><li><p><strong>Learning Opportunity:</strong> Engaging in this Kaggle competition allowed me to delve into real-world data challenges, learning valuable lessons in data preprocessing, feature engineering, and model selection.</p></li><li><p><strong>Feature Pitfall:</strong> Although we experimented with content-based features, they didn&rsquo;t yield satisfactory results. The issue might lie in the process of generating &ldquo;Drama Embeddings,&rdquo; which proved challenging to interpret.</p></li><li><p><strong>Light Data Triumph:</strong> Interestingly, the winning team based their model on only the light data set (with a score of 0.83957). This underscores the fact that with clever strategies and feature utilization, good results can be achieved even with more limited data.</p><p>This also makes me wonder if a better score is achievable using my features with their model (since my features should contain more data)</p></li></ol><p>In retrospect, this experience not only expanded my practical data science skills but also deepened my understanding of the iterative nature of problem-solving in a competitive setting. I&rsquo;m looking forward to trying more challenges like this in the future.</p></div><aside class=tableOfContentContainer id=tableOfContentContainer><h3>Table of Contents</h3><nav id=TableOfContents><ol><li><a href=#understanding-the-challenge-predicting-drama-watching-schedules>Understanding the Challenge: Predicting Drama-Watching Schedules</a><ol><li><a href=#the-data>The data</a></li><li><a href=#measurement-criteria>Measurement criteria</a></li></ol></li><li><a href=#feature-engineering>Feature engineering</a><ol><li><a href=#approach-1-time-based-features>Approach 1: Time based features</a></li><li><a href=#approach-2-content-based-features>Approach 2: Content based features</a></li></ol></li><li><a href=#models>Models</a><ol><li><a href=#benchmark>Benchmark</a></li><li><a href=#cnn>CNN</a></li><li><a href=#cnn--lstm>CNN + LSTM</a></li><li><a href=#xgb>XGB</a></li><li><a href=#ensemble-learning>Ensemble learning</a></li></ol></li><li><a href=#discussion>Discussion</a></li></ol></nav></aside></div><div id=contact_buttons><footer><p>Made by Alexander Nilsson using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://alexnder77.github.io/>Home</a></li><li><a href=https://twitter.com/alexand27264042>Twitter</a></li><li><a href=https://github.com/Alexnder77>GitHub</a></li></ul></footer></div><br><br><script>const header=document.getElementById("header"),navbar=document.getElementById("navbar"),headerImage=document.getElementById("headerImage"),expandIcon=document.getElementById("expandIcon");function handleScroll(){window.scrollY>0?(header.classList.add("scrolled"),navbar.style.display="none"):(header.classList.remove("scrolled"),navbar.style.display="block")}function toggleNavbar(){navbar.style.display=navbar.style.display==="block"?"none":"block"}window.addEventListener("scroll",handleScroll),expandIcon.addEventListener("click",toggleNavbar)</script></body></html>